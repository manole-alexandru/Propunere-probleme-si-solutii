{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cd2d8b-ea4d-47d5-be6b-062279e61e59",
   "metadata": {},
   "source": [
    "# Define a function to evaluate a user result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T18:04:42.944048Z",
     "start_time": "2025-02-06T18:04:42.928603Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "def evaluate_candidate_output(ground_truth_path:str, \n",
    "                              candidate_name: str, \n",
    "                              candidate_output_path: str) -> Tuple[float, List]:\n",
    "    detailed_results = [] \n",
    "    \n",
    "    # Load answer files\n",
    "    output_0 = pd.read_csv(os.path.join(candidate_output_path, 'output_0.csv'))\n",
    "    output_1 = pd.read_csv(os.path.join(candidate_output_path, 'output_1.csv'))\n",
    "    output_2 = pd.read_csv(os.path.join(candidate_output_path, 'output_2.csv'))\n",
    "\n",
    "    #### Evaluate the output_1 file ####\n",
    "    print(f\"Evaluating candidate: {candidate_name}\")\n",
    "\n",
    "    # Check if the output_0 has the expected columns # 'Samples', 'No. Males', 'Average Duration', 'SeniorUsers'\n",
    "    is_output_0_correct = output_0.columns.tolist() == ['Samples', 'No. Males', 'Average Duration', 'SeniorUsers']\n",
    "    score_output_0 = 0\n",
    "    if is_output_0_correct:\n",
    "        print(\"output_0 - columns are correct\")\n",
    "        print(\"restul1\", output_0[\"Samples\"].iloc[0])\n",
    "        if output_0[\"Samples\"].iloc[0] == 9000:\n",
    "            detailed_results.append(10)\n",
    "            score_output_0 += detailed_results[-1]\n",
    "            print(\"Samples column is correct\")\n",
    "\n",
    "        if output_0[\"No. Males\"].iloc[0] == 4443:\n",
    "            detailed_results.append(10)\n",
    "            score_output_0 += detailed_results[-1]\n",
    "            print(\"No. Males column is correct\")\n",
    "\n",
    "        if output_0[\"Average Duration\"].iloc[0] == 15.51:\n",
    "            detailed_results.append(10)\n",
    "            score_output_0 += detailed_results[-1]\n",
    "            print(\"Average Duration column is correct\")\n",
    "\n",
    "        if output_0[\"SeniorUsers\"].iloc[0] == 412:\n",
    "            detailed_results.append(10)\n",
    "            score_output_0 += detailed_results[-1]\n",
    "            print(\"SeniorUsers column is correct\")\n",
    "    else:\n",
    "            detailed_results.extend([0]*4)\n",
    "\n",
    "    ### Evaluate the output_1 file ####\n",
    "    score_output_1 = 0\n",
    "    is_output_1_correct = output_1.columns.tolist() == [\"Calories\"]\n",
    "    if is_output_1_correct:\n",
    "        print(\"output_1 columns are correct\")\n",
    "\n",
    "        # Load the dataset_eval_t dataset that contains the column Calories then compare it with the output_2 price column using MAE metric\n",
    "        # Do the mae for each row then sum all the mae and divide it by the number of rows\n",
    "        dataset_eval_t = pd.read_csv(os.path.join(ground_truth_path, 'task1_dataset_eval_t.csv'))\n",
    "\n",
    "        mae = (dataset_eval_t[\"Calories\"] - output_1[\"Calories\"]).abs().sum() / len(dataset_eval_t)\n",
    "        print(\"MAE: \", mae)\n",
    "\n",
    "        # Assign scores based on MAE value\n",
    "        import bisect\n",
    "        ranges = [8.5, 9, 10, 12]\n",
    "        scores = [40, 30, 20, 10]\n",
    "\n",
    "        index = bisect.bisect_left(ranges, mae)\n",
    "        if index < len(scores):\n",
    "            score_output_1 += scores[index]\n",
    "\n",
    "        detailed_results.append(score_output_1)\n",
    "\n",
    "        print(\"Took the score: \", score_output_1)\n",
    "    else:\n",
    "        detailed_results.append(0)\n",
    "\n",
    "    score_output_2 = 0\n",
    "    is_output_2_correct = output_2.columns.tolist() == [\"Calories\"]\n",
    "    if is_output_2_correct:\n",
    "        print(\"output_2 columns are correct\")\n",
    "\n",
    "        # Load the dataset_eval_t dataset that contains the column Calories then compare it with the output_2 price column using MAE metric\n",
    "        # Do the mae for each row then sum all the mae and divide it by the number of rows\n",
    "        dataset_eval_t = pd.read_csv(os.path.join(ground_truth_path, 'task2_dataset_eval_t.csv'))\n",
    "\n",
    "        mae = (dataset_eval_t[\"Calories\"] - output_2[\"Calories\"]).abs().sum() / len(dataset_eval_t)\n",
    "        print(\"MAE: \", mae)\n",
    "\n",
    "        # Assign scores based on MAE value\n",
    "        import bisect\n",
    "        ranges = [18, 23, 26, 30]\n",
    "        scores = [20, 15, 10, 5]\n",
    "\n",
    "        index = bisect.bisect_left(ranges, mae)\n",
    "        if index < len(scores):\n",
    "            score_output_2 += scores[index]\n",
    "\n",
    "        detailed_results.append(score_output_2)\n",
    "\n",
    "        print(\"Took the score: \", score_output_2)\n",
    "    else:\n",
    "        detailed_results.append(0)\n",
    "\n",
    "\n",
    "    # Calculate the total score\n",
    "    total_score = score_output_0 + score_output_1 + score_output_2\n",
    "    print(\"Total score: \", total_score)\n",
    "\n",
    "    return total_score, detailed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c68e5-f521-482e-bf18-d94db9a5bab1",
   "metadata": {},
   "source": [
    "# Then go through all and create a csv files with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7332ff592eebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Candidat_avansat', 'Candidat_incepator']\n",
      "Evaluating candidate: Candidat_avansat\n",
      "output_0 - columns are correct\n",
      "restul1 9000\n",
      "Samples column is correct\n",
      "No. Males column is correct\n",
      "Average Duration column is correct\n",
      "SeniorUsers column is correct\n",
      "output_1 columns are correct\n",
      "MAE:  8.360868935370371\n",
      "Took the score:  40\n",
      "output_2 columns are correct\n",
      "MAE:  17.735515802924297\n",
      "Took the score:  20\n",
      "Total score:  100\n",
      "Evaluating candidate: Candidat_incepator\n",
      "output_0 - columns are correct\n",
      "restul1 9000\n",
      "Samples column is correct\n",
      "No. Males column is correct\n",
      "Average Duration column is correct\n",
      "SeniorUsers column is correct\n",
      "output_1 columns are correct\n",
      "MAE:  9.30688678275\n",
      "Took the score:  20\n",
      "output_2 columns are correct\n",
      "MAE:  27.102977750999997\n",
      "Took the score:  5\n",
      "Total score:  65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Detailed</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candidat_avansat</td>\n",
       "      <td>[10, 10, 10, 10, 40, 20]</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candidat_incepator</td>\n",
       "      <td>[10, 10, 10, 10, 20, 5]</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                  Detailed  Total\n",
       "0    Candidat_avansat  [10, 10, 10, 10, 40, 20]    100\n",
       "1  Candidat_incepator   [10, 10, 10, 10, 20, 5]     65"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take all candidates and evaluate them. Create a final csv with outputs \n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Open the outputs from candidates\n",
    "candidates_path = Path(\"../Solutii\")\n",
    "folder_candidati = [f.name for f in candidates_path.iterdir() if f.is_dir()]\n",
    "print(folder_candidati)\n",
    "\n",
    "# Open each candidates and run the evaluator\n",
    "candidate_results = []\n",
    "for candidate_name in folder_candidati:\n",
    "    if candidate_name[0] == '.':\n",
    "        continue \n",
    "        \n",
    "    candidat_path = candidates_path / candidate_name\n",
    "    \n",
    "    relative_path = str(Path(candidat_path))\n",
    "    total_score, detailed_results = evaluate_candidate_output(ground_truth_path=\"Dataset\",\n",
    "                              candidate_name=candidate_name,\n",
    "                              candidate_output_path=relative_path)\n",
    "\n",
    "    candidate_results.append({'Name' : candidate_name, 'Detailed': detailed_results, 'Total' : total_score})\n",
    "\n",
    "df = pd.DataFrame(candidate_results)\n",
    "df = df.sort_values(by=\"Total\", ascending=False)  # Sort in descending order (highest score first)\n",
    "df.to_csv(candidates_path/ \"rezultate.csv\", index=False)\n",
    "    \n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
